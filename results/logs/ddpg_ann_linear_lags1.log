2025-11-28 03:31:28 - ddpg_ann_linear_lags1 - INFO - Starting training: ddpg_ann_linear_lags1
2025-11-28 03:31:28 - ddpg_ann_linear_lags1 - INFO - Loading economy model...
2025-11-28 03:31:28 - ddpg_ann_linear_lags1 - INFO - 
Training with critic_nodes=1, actor_nodes=None
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - Steady-state reward: -54.3901
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - New best agent found!
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - 
Best agent saved to: results/checkpoints\ddpg_ann_linear_lags1.pth
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - Best configuration: {'critic_nodes': 1, 'actor_nodes': None, 'steady_state_reward': np.float64(-54.39007063332249)}
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - Policy parameters saved to: results/checkpoints\ddpg_ann_linear_lags1_params.pkl
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - 
Optimized Policy Parameters:
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO -   alpha_0: 0.1320
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO -   beta_y_0: 0.1342
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO -   beta_y_1: -0.7053
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO -   beta_pi_0: 0.8564
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO -   beta_pi_1: 1.2166
2025-11-28 03:32:27 - ddpg_ann_linear_lags1 - INFO - Training complete!
